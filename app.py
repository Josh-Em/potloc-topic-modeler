from flask import Flask, render_template, request, jsonify, flash, redirect, url_for
import re
import pandas as pd
import numpy as np
from gensim import corpora, models
from gensim.utils import simple_preprocess
from gensim.parsing.preprocessing import STOPWORDS
from nltk.stem import WordNetLemmatizer
from nltk.stem.porter import *
from werkzeug.utils import secure_filename
import nltk
import logging
from openai import OpenAI

# Set the OpenAI API key
api_key = "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"
client = OpenAI(api_key=api_key)

nltk.download('wordnet')

# Configure logging
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# TopicModel class definition
class TopicModel:
    def __init__(self):
        self.lda_model = None
        self.dictionary = None
        self.documents = []
        self.named_topics = {}

    # Function to clean text
    def clean_text(self, text):
        if text is not None and isinstance(text, str):
            text = text.lower()
            text = text.replace('\\n', ' ')
            text = re.sub(r'http\S+|www\S+', '', text)
            text = re.sub(' +', ' ', text)
            return text.strip()
        return ''

    # Function to tokenize and lemmatize text
    def tokenize_lemmatize(self, text):
        return [WordNetLemmatizer().lemmatize(token) for token in simple_preprocess(text) if token not in STOPWORDS]

    # Function to process texts (tokenize and lemmatize text for each document)
    def process_texts(self, texts):
        return [self.tokenize_lemmatize(text) for text in texts]

    # Function to process data from input file
    def process_data(self, file):
        df = pd.read_csv(file, delimiter=';')

        # Clean text data in the DataFrame
        df['question_title'] = df['question_title'].apply(self.clean_text)
        df['question_content'] = df['question_content'].apply(self.clean_text)
        df['best_answer'] = df['best_answer'].apply(self.clean_text)

        # Combine question_title, question_content, and best_answer into a single text field
        df['combined_text'] = df['question_title'] + ' ' + df['question_content'].fillna('') + ' ' + df['best_answer']

        self.documents = df['combined_text'].tolist()

        # Generate table with a sample of processed data
        head = df.head(3)
        header = ['ID', 'Question Title', 'Question Content', 'Best Answer', 'Combined Text']
        rows = head.values.tolist()

        table_html = '<table border="1"><tr>'
        for h in header:
            table_html += f'<th>{h}</th>'
        table_html += '</tr>'
        for row in rows:
            table_html += '<tr>'
            for cell in row:
                table_html += f'<td>{cell}</td>'
            table_html += '</tr>'
        table_html += '</table>'

        return table_html

    # Function to train the LDA model
    def train_model(self):
        if not self.documents:
            return {"message": "No data available for training"}, 400

        try:
            # Tokenize and lemmatize the input documents
            tokenized_texts = self.process_texts(self.documents)

            # Create a dictionary and a corpus from the tokenized texts
            dictionary = corpora.Dictionary(tokenized_texts)
            corpus = [dictionary.doc2bow(text) for text in tokenized_texts]

            # Train an LDA model with the given corpus and dictionary
            self.lda_model = models.ldamodel.LdaModel(corpus, num_topics=30, id2word=dictionary, passes=5,
                                                      random_state=42)
            self.dictionary = dictionary

            # Print the topics generated by the model
            topics = self.lda_model.print_topics(num_topics=50, num_words=20)
            topics_list = []
            for i, (_, topic_words) in enumerate(topics):
                words = " ".join(re.findall(r'"[^"]*"', topic_words))  # Extract words (strip out probabilities)
                topics_list.append({"id": i + 1, "words":(words)})

            return {"message": "Successfully trained the LDA model", "topics": topics_list}

        except Exception as e:
            logging.error(f"Error training the LDA model: {str(e)}")
            return {"message": f"Error training the LDA model: {str(e)}"}, 500

    # Function to generate topic names using OpenAI
    def name_topics(self, topics):
        if not topics:
            return {"message": "No topics provided"}, 400

        topic_dict = {}
        for topic_num, topic_words in enumerate(topics):
            joined_topic_words = " ".join(topic_words)

            # Request topic titles from the OpenAI API
            response = client.chat.completions.create(
                model="gpt-3.5-turbo-16k-0613",
                messages=[
                    {
                        "role": "system",
                        "content": "You are a helpful assistant"
                    },
                    {
                        "role": "user",
                        "content": (
                            f"Consider the following group of words. I would like you to output a single "
                            f"topic name for this group. Only output the topic name and nothing else:\n"
                            f"---\n{joined_topic_words}\n---")
                    }
                ],
                temperature=1,
                max_tokens=200,
                top_p=1,
                frequency_penalty=0,
                presence_penalty=0
            )

            topic_title = response.choices[0].message.content.strip()
            topic_dict[str(topic_num + 1)] = {
                "title": topic_title,
                "words": topic_words
            }
        self.named_topics = topic_dict
        return self.named_topics

    # Function to predict the topic of a given text using the trained LDA model
    def predict_topic(self, text):
        if not self.lda_model or not self.dictionary:
            return {"message": "No LDA model available for prediction"}, 400

        if not text:
            return {"message": "No text provided for prediction"}, 400

        try:
            # Clean, tokenize, and lemmatize the input text
            tokenized_text = self.tokenize_lemmatize(self.clean_text(text))
            
            # Convert the tokenized text to its Bag-of-Words (BoW) representation
            bow_vector = self.dictionary.doc2bow(tokenized_text)
            
            # Determine topic probabilities for the input text using the trained LDA model
            sorted_topic_probs = sorted(self.lda_model[bow_vector], key=lambda x: -x[1])
            
            # Identify the topic with the highest probability
            most_probable_topic = sorted_topic_probs[0][0] + 1

            return {
                "topic": most_probable_topic,
                "title": self.named_topics[str(most_probable_topic)]["title"],
                "words": self.named_topics[str(most_probable_topic)]["words"]
            }
        except Exception as e:
            logging.error(f"Error predicting topic: {str(e)}")
            return {"message": f"Error predicting topic: {str(e)}"}, 500


# Initialize the Flask application and create a TopicModel instance
app = Flask(__name__)
topic_modeler = TopicModel()

# Route for the index/home page
@app.route('/')
def index():
    return render_template('index.html')

# Route for processing and cleaning data from the uploaded CSV file
@app.route('/process_data', methods=['POST'])
def process_data():
    if 'csv_file' not in request.files:
        return 'No file attached', 400

    file = request.files['csv_file']

    try:
        result = topic_modeler.process_data(file)
        return result
    except Exception as e:
        logging.error(f"Error processing data: {str(e)}")
        return {"message": f"Error processing data: {str(e)}"}, 500

# Route for training the LDA model
@app.route('/train_model', methods=['POST'])
def train_model():
    try:
        result = topic_modeler.train_model()
        return result
    except Exception as e:
        logging.error(f"Error training the LDA model: {str(e)}")
        return {"message": f"Error training the LDA model: {str(e)}"}, 500

# Route for naming topics using OpenAI
@app.route('/name_topics', methods=['POST'])
def name_topics():
    topics = request.get_json(force=True).get('topics')
    if not topics:
        return {"message": "No topics provided"}, 400

    try:
        result = topic_modeler.name_topics(topics)
        return jsonify(result)
    except Exception as e:
        logging.error(f"Error naming topics: {str(e)}")
        return {"message": f"Error naming topics: {str(e)}"}, 500

# Route for predicting the topic of a given input text
@app.route('/predict_topic', methods=['POST'])
def predict_topic():
    data = request.get_json(force=True)
    text = data.get('text', '').strip()

    if not text:
        return {"message": "No text provided for prediction"}, 400

    try:
        result = topic_modeler.predict_topic(text)
        return result
    except Exception as e:
        logging.error(f"Error predicting topic: {str(e)}")
        return {"message": f"Error predicting topic: {str(e)}"}, 500

# Run the Flask app
if __name__ == '__main__':
    app.run(debug=True)